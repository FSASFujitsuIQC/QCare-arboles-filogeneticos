{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589184d0-144b-4776-b619-3ef640a06a10",
   "metadata": {},
   "source": [
    "# PHYLOGENETIC TREES WITH DIGITAL ANNEALER INSPIRED BY GRAPH SPLITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04cc67-5c8c-41c9-8086-ced6c39b612b",
   "metadata": {},
   "source": [
    "The main objective of this method is to consecutively divide a set of nodes or species with Fujitsu's Digital Annealer until a phylogenetic tree is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebecabc3-36bf-4f43-8da7-262f4dc2b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports related to the DA\n",
    "from dadk.QUBOSolverCPU import *\n",
    "from dadk.Solution_SolutionList import *\n",
    "from dadk.BinPol import *\n",
    "\n",
    "# other imports\n",
    "from openpyxl import load_workbook\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb32316-4a2e-42b5-b7d9-0343d476e405",
   "metadata": {},
   "source": [
    "## Data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87f131-a2b7-4241-884f-93b4719305e6",
   "metadata": {},
   "source": [
    "In order to be able to obtain a phylogenetic tree, we need a set of species and a measurement that allows us to determine how close they are to each other. This would constitute the nodes and the edges of the graph we are going to cut. \n",
    "\n",
    "For that, we have originally taken datasets from [Phylome DB](https://phylomedb.org/phylomes?s=expl), a database webpage of different phylomes that offers both the standard accepted phylogenetic tree and the amino acid sequences of the species. With this amino acid sequence, in FASTA format, we have used the $\\verb|func_cleanfasta|$ to clean up the .fasta files and fed it to BLAST+. The program analyzes its database of aminoacid sequences and following a local comparison algorithm, returns several metrics, among which we find the bit scores. \n",
    "\n",
    "Bit scores are a good metric that take several characteristics into account to determine how closely related the two species are. They are not normalized when they first come out of BLAST+, so the first step to get a proper matrix of similarities is to normalize them. Let us see how we do that with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1f179e-baa0-4dd5-b6d6-f23e80e1cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SIMILARITY MATRIX (EXCEL FILE)\n",
    "\n",
    "def import_from_excel(filename):\n",
    "    \"\"\"\n",
    "    Imports a similarity matrix from an Excel file and returns a list of nodes and a bitscore matrix.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        nodes (list): List of unique node names.\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open up the Excel file\n",
    "    workbook = load_workbook(filename)\n",
    "    \n",
    "    # Get the first sheet\n",
    "    worksheet = workbook.worksheets[0]\n",
    "    \n",
    "    column_list = []\n",
    "    \n",
    "    # Obtain a list of lists (each element is a column of the file)\n",
    "    for c in worksheet.columns:\n",
    "        row = [cell.value for cell in c]\n",
    "        column_list.append(row)\n",
    "    \n",
    "    # Clean up header and select nodes_query column, nodes_sub column and bit_score column\n",
    "    nodes_query = column_list[0][1:]\n",
    "    nodes_sub = column_list[1][1:]\n",
    "    bit_scores = column_list[11][1:]\n",
    "    \n",
    "    # Transform bitscores to float type\n",
    "    bit_scores = [float(i) for i in bit_scores]\n",
    "\n",
    "    # Run the subroutine that deletes duplicate nodes\n",
    "    nodes = extract_nodes(nodes_query)\n",
    "\n",
    "    # Run the subroutine that creates the matrix shape from the bitscore column\n",
    "    bitscore_matrix = extract_matrix(nodes_query, nodes_sub, nodes, bit_scores)\n",
    "\n",
    "    return(nodes, bitscore_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688abe40-faff-4302-9d97-dd7f82112c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SIMILARITY MATRIX (TSV FILE)\n",
    "\n",
    "def import_from_tsv(filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Imports a similarity matrix from a tsv file and returns a list of nodes and a bitscore matrix.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        nodes (list): List of unique node names.\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    tsv_path = filename\n",
    "    column_list = []\n",
    "    \n",
    "    # Reads all rows as lists first\n",
    "    with open(tsv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        rows = list(reader)\n",
    "    \n",
    "    # Transpose rows for columns\n",
    "    for col in zip(*rows):\n",
    "        column_list.append(list(col))\n",
    "    \n",
    "    # Clean up header and select nodes_query column, nodes_sub column and bit_score column\n",
    "    nodes_query = column_list[0]\n",
    "    nodes_sub = column_list[1]\n",
    "    bit_scores = column_list[11]\n",
    "    \n",
    "    # Transform bitscores to float type\n",
    "    bit_scores = [float(i) for i in bit_scores]\n",
    "\n",
    "    # Run the subroutine that deletes duplicate nodes\n",
    "    nodes = extract_nodes(nodes_query)\n",
    "\n",
    "    # Run the subroutine that creates the matrix shape from the bitscore column\n",
    "    bitscore_matrix = extract_matrix(nodes_query, nodes_sub, nodes, bit_scores)\n",
    "\n",
    "    return(nodes, bitscore_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0fdcb-c6fe-4157-8a37-1ea8d62a5864",
   "metadata": {},
   "source": [
    "The reason for $\\verb|nodes_query|$ and $\\verb|nodes_sub|$ to exist is that BLAST+ first creates a database with our .fasta file and calls the species in that database 'Subject'. Then it iteratively compares the sequences in the original .fasta ('Queries') with the ones on the database, so we have two columns with all the possible pairs in the set. To have a proper array with only the nodes (sequences) for future use, we will search through the first column and get the unique names out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8576c703-c137-4e3d-895f-736bfeee8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes(nodes_query):\n",
    "    \"\"\"\n",
    "    Subroutine that extracts unique nodes from the nodes_query list.\n",
    "\n",
    "    Args:\n",
    "        nodes_query (list): Original query nodes list.\n",
    "\n",
    "    Returns:\n",
    "        nodes (list): List of unique node names.\n",
    "    \"\"\"\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    # we initialize the current node selected\n",
    "    # the nodes are in order, so we just need to check when the name changes\n",
    "    current_node_name = nodes_query[0]\n",
    "    nodes.append(current_node_name)\n",
    "    \n",
    "    # we inspect all the nodes in nodes_query\n",
    "    for i in range(len(nodes_query)):\n",
    "        # select a new node only when the name changes\n",
    "        if nodes_query[i] != current_node_name:\n",
    "            nodes.append(nodes_query[i])\n",
    "            # we update current_node_name\n",
    "            current_node_name = nodes_query[i]\n",
    "    \n",
    "    return(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01232f-1032-4bbe-8730-294bc6a537bd",
   "metadata": {},
   "source": [
    "The bit scores are a measurement of how closely related the species are, so the bigger the score, the bigger the simmilarity. The bit score matrix will be, then, a simmilarity matrix.\n",
    "\n",
    "Now, we will normalize the bit scores. We will use the formula\n",
    "\n",
    "$$ Norm_{bit(i,j)} = \\frac{bit(i,j)}{\\mathrm{mean}\\{bit(i,i), bit(j,j)\\}}*100. $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161cb34-6b1e-498c-9140-b7b2b06d5e15",
   "metadata": {},
   "source": [
    "We must also rearrange the $\\verb|bit_scores_norm|$ array into a matrix. This is not a trivial step, as the total length of the array is not exactly $nodes \\times nodes $, since some species are so distantly related that BLAST+ has purged them out. For those cases, we will asign the default zero to the edge between those nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77490104-ee94-4532-9de1-b0f1b919475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matrix(nodes_query, nodes_sub, nodes, bit_scores):\n",
    "\n",
    "    \"\"\"\n",
    "    Subroutine that builds the structure of the bitscore matrix from the nodes_query and \n",
    "    nodes_sub list and the values from the normalized the bit_scores list.\n",
    "\n",
    "    Args:\n",
    "        nodes_query (list): List of query nodes.\n",
    "        nodes_sub (list): List of subject nodes.\n",
    "        nodes (list): List of unique node names.\n",
    "        bit_scores (list): List of bit scores.\n",
    "\n",
    "    Returns:\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    n_total = len(bit_scores)\n",
    "    \n",
    "    bit_scores_norm = []\n",
    "    \n",
    "    # We iterate over the entire array of bit scores\n",
    "    \n",
    "    for k in range(n_total):\n",
    "    \n",
    "        # We save the name of the query and subject\n",
    "        query_name = nodes_query[k]\n",
    "        sub_name = nodes_sub[k]\n",
    "    \n",
    "        # We iterate over the rest of the list finding the bit(query,query) = bit(i,i)\n",
    "        # and bit(subject,subject) = bit(j,j)\n",
    "    \n",
    "        for i in range(n_total):\n",
    "            \n",
    "            if nodes_query[i] == query_name and nodes_sub[i] == query_name:\n",
    "                bit_i_i = bit_scores[i]\n",
    "    \n",
    "            if nodes_query[i] == sub_name and nodes_sub[i] == sub_name:\n",
    "                bit_j_j = bit_scores[i]\n",
    "    \n",
    "        # Calculate the mean\n",
    "        mean_scores = (bit_i_i + bit_j_j)/2\n",
    "    \n",
    "        # Apply normalization formula\n",
    "        bit_scores_norm.append(bit_scores[k]*100/mean_scores)\n",
    "        \n",
    "\n",
    "    ### BIT SCORE MATRIX BUILD ###\n",
    "    \n",
    "    bitscore_matrix = np.zeros([len(nodes),len(nodes)])\n",
    "    \n",
    "    for k in range(n_total):\n",
    "    \n",
    "        # for each element in bit_scores_norm, we search for the corresponding\n",
    "        # indexes (matching names) in the nodes array, thus we find the\n",
    "        # corresponding column and row in the matrix\n",
    "        \n",
    "        index_query = nodes.index(nodes_query[k])\n",
    "        index_sub = nodes.index(nodes_sub[k])\n",
    "        bitscore_matrix[index_query,index_sub] = bit_scores_norm[k]\n",
    "\n",
    "\n",
    "    ### TRIANGULATION ###\n",
    "\n",
    "    # The matrix must be symmetrical and sometimes it is not symmetrical when it comes\n",
    "    # directly out of the bitscore list values, so we force the symmetry by \n",
    "    # calculating the mean of the corresponding values    \n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(nodes)):\n",
    "            \n",
    "            if bitscore_matrix[i][j] != bitscore_matrix[j][i]:\n",
    "                # mean between element (i,j) and element (j,i)\n",
    "                mean_score = (bitscore_matrix[i][j] + bitscore_matrix[j][i])/2\n",
    "                # reset value of elements (i,j) and (j,i) to the new mean\n",
    "                bitscore_matrix[i][j] = mean_score\n",
    "                bitscore_matrix[j][i] = mean_score\n",
    "    \n",
    "            # DIAG ZEROS #\n",
    "            # We make the diagonal values to be zero to avoid the creation of an edge \n",
    "            # between an element and itself\n",
    "    \n",
    "            if i == j:\n",
    "                bitscore_matrix[i][j]=0\n",
    "\n",
    "    return(bitscore_matrix)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc99857-df40-4b05-919c-4a531b3e9050",
   "metadata": {},
   "source": [
    "We find an interesting result when printing this matrix, which is that it is not exactly symmetrical. This is due to the algorithm that BLAST+ uses to compare queries against subjects. For example, if the amino acid sequence of a certain species is too short, it may yield different results when comparing that species with another as subject-query VS query-subject. In order to fix this, we have decided to triangulate the matrix by taking the mean between the corresponding entries $\\mathrm{mean}(\\verb|bitscore_matrix[i][j]|, \\verb|bitscore_matrix[j][i]|)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce55e9-eed9-44f7-b95d-52fcf49e5d1d",
   "metadata": {},
   "source": [
    "## NMcutDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a2b9ad-a90a-4d78-8ab9-09aaea119aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to hide the output of the QUBO solver\n",
    "\n",
    "def _hide_pol_info(pol):\n",
    "        pol.user_data['hide_scaling_info'] = True\n",
    "        pol.user_data['hide_sampling_info'] = True\n",
    "        return pol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0e42d-5dea-42ef-8ac2-4d9ced2bd536",
   "metadata": {},
   "source": [
    "### MinCut\n",
    "\n",
    "We are looking to divide the graph of all possible connections (all-to-all) in a way that minimizes the relationships between groups of species. This is a classical MinCut problem,\n",
    "\n",
    "$$ Min_{cut} = \\sum_{i=1}^{n-1}\\sum_{j=i+1}^n d_{ij}(x_i - x_j)^2, \\qquad x_i=\\{0,1\\}. $$\n",
    "\n",
    "However, if we repeatedly apply this method without any pelanization, we realize that the algorithm tends to isolate one node VS rest, resulting in pectinate trees. In order to avoid this, a balance penalization has been added to force the choosing of all possible combinations of nodes\n",
    "\n",
    "$$ Min_{cut} = \\sum_{i=1}^{n-1}\\sum_{j=i+1}^n d_{ij}(x_i - x_j)^2 + \\alpha \\left( \\sum_{i=1}^n x_i^1 - c \\right)^2, $$\n",
    "\n",
    "where $c$ is the number of nodes to separate in that iteration. For example, if we have $8$ nodes, we would want to have the combinations $1:7$, $2:6$, $3:5$ and $4:4$, so $c$ would take the values $c=\\{1,2,3,4\\}$, respectively. The DA is in charge of finding the minimun energy for each of those combinations, so we wouldn't need to analyze combinations like $5:3$ as it would yield the same energy as $3:5$.\n",
    "\n",
    "### Ncut\n",
    "\n",
    "As a way to ponder which cut $c:(n-c)$ is the best, a post-processing metric was implemented, called the Ncut. Ncut values, not only the similarity between the species within each node, but also the dissimilarities between the two clusters as a whole. Therefore, we would be avoiding the problem of singleing out a node each time. The formula for Ncut is the following:\n",
    "\n",
    "$$ N_{cut} = \\frac{Min_{cut}}{assoc(A,V)} + \\frac{Min_{cut}}{assoc(B,V)} $$\n",
    "\n",
    "with\n",
    "\n",
    "$$ assoc(X,V) = \\sum_{u \\in X, t \\in V} d_{ut}, \\qquad X = \\{A, B\\}.$$\n",
    "\n",
    "Once the minimum Ncut is chosen, that division is applied to the nodes and the process repeats again for each of the two new clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f228d069-1319-4f37-be3b-0366782b115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QUBO(nodes, bitscore_matrix, c, alpha):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates the QUBO polynomial for the NMCutDA problem.\n",
    "\n",
    "    Args:\n",
    "        nodes (list): List of unique nodes.\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "        c (int): Desired number of nodes in the first cluster.\n",
    "        alpha (float): Weighting factor for the penalization term.\n",
    "\n",
    "    Returns:\n",
    "        nodes (list): List of unique node names.\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # shape of the set of variables for this QUBO\n",
    "    my_constant_bits = np.full((len(nodes),), -1, np.int8) \n",
    "    my_varshapeset = VarShapeSet(BitArrayShape(name='x', shape=(len(nodes),), axis_names = ['nodes'], constant_bits = my_constant_bits))\n",
    "    # freeze the shape for all BinPols\n",
    "    BinPol.freeze_var_shape_set(my_varshapeset)\n",
    "    \n",
    "\n",
    "    ### FIRST POLYNOM: MinCut ###\n",
    "    \n",
    "    # Open an empty polynomial with the frozen shape\n",
    "    H_d = BinPol()\n",
    "\n",
    "    # run for all possible values of i and j\n",
    "    for i in range(len(nodes)-1):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            # open an auxiliary polynomial\n",
    "            H_ij = BinPol()\n",
    "            # create term (x_i - x_j)\n",
    "            H_ij.add_term(1, ('x',i))\n",
    "            H_ij.add_term(-1, ('x',j))\n",
    "            # power of 2 (x_i - x_j)^2\n",
    "            H_ij.power(2)\n",
    "            # add coefficient d_ij\n",
    "            bit_coef = bitscore_matrix[i][j].item() # change to float (DA doesnt like numpy.float) \n",
    "            H_ij = bit_coef*H_ij\n",
    "            # add auxiliary polynomial to the total polynomial (sum)\n",
    "            H_d.add(H_ij)\n",
    "\n",
    "    \n",
    "    ### SECOND POLYNOM: penalization ###\n",
    "    \n",
    "    # Auxiliary polynomial for sum(x_i)\n",
    "    H_alpha_aux = BinPol()\n",
    "    for i in range(len(nodes)):\n",
    "        H_alpha_aux.add_term(1, ('x',i))\n",
    "    # substract c and power of 2\n",
    "    H_alpha = alpha*((H_alpha_aux-c).power(2))\n",
    "    \n",
    "    \n",
    "    ### Total QUBO ###\n",
    "    \n",
    "    H_qubo = H_d + H_alpha\n",
    "    H_qubo = _hide_pol_info(H_qubo)\n",
    "\n",
    "    return(H_qubo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7641c44-f044-4c97-bc5b-7b0b9eb34841",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUBO FUNCTION ITERATING C ###\n",
    "\n",
    "def N_cut_func(nodes, bitscore_matrix, edges_times):\n",
    "\n",
    "    \"\"\"\n",
    "    Selects the cut c:(n-c) with the lowest Ncut.\n",
    "\n",
    "    Args:\n",
    "        nodes (list): List of unique nodes.\n",
    "        bitscore_matrix (numpy.ndarray): 2D numpy array representing the bitscore matrix.\n",
    "        edges_times (str): 'single' if edges are counted once, 'double' if edges are counted twice.\n",
    "\n",
    "    Returns:\n",
    "        best_min_cut (float): Minimum Mincut value for the best partition.\n",
    "        best_N_cut (float): Minimum Ncut value for the best partition.\n",
    "        best_N_cut_array (numpy.ndarray): Array indicating the best partition of nodes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # We choose alpha high enough that the DA respects the\n",
    "    # value of c chosen.\n",
    "    alpha = 1000\n",
    "\n",
    "    # Options for the DA local Solver\n",
    "    solver = QUBOSolverCPU(\n",
    "        number_iterations = 200000,\n",
    "        number_runs = 10,\n",
    "        scaling_bit_precision = 32,\n",
    "        scaling_action = ScalingAction.AUTO_SCALING)\n",
    "\n",
    "    # We initialize N_cut to a high enough value\n",
    "    N_cut = 10**50\n",
    "\n",
    "    # Start of the loop, with c ranging from 1 to nodes/2 (all possible partitions)\n",
    "    for c in range(1, int(len(nodes)/2)+1):\n",
    "    \n",
    "        # Create the QUBO with the corresponding c\n",
    "        H_qubo = QUBO(nodes, bitscore_matrix, c, alpha)\n",
    "    \n",
    "        ### SOLVER ###\n",
    "        \n",
    "        solution_list = solver.minimize(H_qubo)\n",
    "        solution = solution_list.min_solution\n",
    "\n",
    "        # list of 0 and 1 indicating the partition\n",
    "        min_cut_array = solution.configuration\n",
    "\n",
    "        ### CHECK CONDITION ###\n",
    "\n",
    "        # We check that the partition number c was met,\n",
    "        # if not, we relaunch the solver with a higher alpha\n",
    "\n",
    "        # Auxiliary counter to check how many times the condition c\n",
    "        # was not met and to restore alpha to its original value\n",
    "        counter = 0\n",
    "        \n",
    "        while sum(min_cut_array) != c:\n",
    "            # update counter\n",
    "            counter += 1\n",
    "            # make alpha bigger\n",
    "            alpha = alpha*10\n",
    "            # create QUBO again with new alpha\n",
    "            H_qubo = QUBO(nodes, bitscore_matrix, c, alpha)\n",
    "            # new solution list\n",
    "            solution_list = solver.minimize(H_qubo)\n",
    "            solution = solution_list.min_solution\n",
    "            min_cut_array = solution.configuration\n",
    "\n",
    "        # restore original value of alpha\n",
    "        alpha = alpha/(10**counter)\n",
    "            \n",
    "    \n",
    "        ### N-CUT ###\n",
    "        \n",
    "        # compute the polynomial with the min_cut solution list to know \n",
    "        # the energy of the minimum cut\n",
    "        min_cut = H_qubo.compute(min_cut_array)\n",
    "\n",
    "        # We initialize assoc_A_V and assoc_B_V and calculate their values\n",
    "    \n",
    "        assoc_A_V = 0\n",
    "        assoc_B_V = 0\n",
    "\n",
    "        # It is not clear in the original assoc(A,V) formula if the edges should be counted \n",
    "        # once or twice. Both ways are implemented but 'twice' = 'double' was finally\n",
    "        # selected for yielding better results\n",
    "\n",
    "        ################################################### edges counted twice\n",
    "\n",
    "        if edges_times == 'double':\n",
    "        \n",
    "            # index i refers to cluster A\n",
    "            for i in range(len(nodes)):\n",
    "                # index j runs over all nodes (V = A + B)\n",
    "                for j in range(len(nodes)):\n",
    "            \n",
    "                    # sum of the edges associated to cluster A\n",
    "                    if min_cut_array[i] == 0:\n",
    "                        assoc_A_V += bitscore_matrix[i][j]\n",
    "            \n",
    "                    # sum of the edges associated to cluster B\n",
    "                    elif min_cut_array[i] == 1:\n",
    "                        assoc_B_V += bitscore_matrix[i][j]\n",
    "\n",
    "\n",
    "        ################################################### edges counted once\n",
    "\n",
    "        if edges_times == 'single':\n",
    "        \n",
    "            for i in range(len(nodes)):\n",
    "                for j in range(len(nodes)):\n",
    "                \n",
    "                    if min_cut_array[i] == 0:\n",
    "                        # add all edges between A and B\n",
    "                        if min_cut_array[j] != 0:\n",
    "                            assoc_A_V += bitscore_matrix[i][j]\n",
    "                        # avoid edges related to nodes already added in A (i>=j)\n",
    "                        elif i<j:\n",
    "                            assoc_A_V += bitscore_matrix[i][j]\n",
    "                \n",
    "                    elif min_cut_array[i] == 1:\n",
    "                        # add all edges between B and A\n",
    "                        if min_cut_array[j] != 1:\n",
    "                            assoc_B_V += bitscore_matrix[i][j]\n",
    "                        # avoid edges related to nodes already added in B (i>=j)\n",
    "                        elif i<j:\n",
    "                            assoc_B_V += bitscore_matrix[i][j]\n",
    "\n",
    "        ######################################################\n",
    "\n",
    "        # Prevent extreme cases in which nodes dont have edges (edges = 0, thus divide by zero)\n",
    "\n",
    "        if assoc_A_V == 0:\n",
    "            assoc_A_V = 1\n",
    "        if assoc_B_V == 0:\n",
    "            assoc_B_V = 1\n",
    "\n",
    "        # Formula for Ncut\n",
    "    \n",
    "        current_N_cut = min_cut/assoc_A_V + min_cut/assoc_B_V\n",
    "\n",
    "        # We keep current_N_cut if it's lower than before (minimum)\n",
    "    \n",
    "        if current_N_cut < N_cut:\n",
    "    \n",
    "            best_min_cut = min_cut\n",
    "            best_N_cut = current_N_cut\n",
    "            best_N_cut_array = min_cut_array\n",
    "\n",
    "            # Update old N_cut with current value\n",
    "            \n",
    "            N_cut = best_N_cut   \n",
    "\n",
    "    return(best_min_cut, best_N_cut, best_N_cut_array)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4e3f2-f1e8-400f-a8f8-9e98852631a1",
   "metadata": {},
   "source": [
    "This function that we just saw $\\verb|N_cut_func|$ chooses the best $c:(n-c)$ based on the Ncut value. It is now our turn to apply these changes and separate the node arrays iteratively. We are dealing with a binary split, so if we wanted to save the variables each time, they would grow exponentially. In order to optimize this, we have programmed a function that recursively calls itself until a final separation array is obtained.\n",
    "\n",
    "The way to 'mark' the splits each time has been coded in binary. The first split determines a 'path' ($0$ if the DA has chosen $x_i = 0$ and $1$ if $x_i=1$). Equivalently, we can think of this method as a way to code if the branch goes 'up' ($0$) or 'down' ($1$), for example. That way, we can keep track of all the node splits and reconstruct the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daffffe-f50d-44a8-8f71-f7c9a2e7dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes(node_array, cut_array):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that assigns the split nodes to two new arrays based\n",
    "    on the solution array of the DA.\n",
    "\n",
    "    Args:\n",
    "        node_array (list): original list of nodes with the species names\n",
    "        cut_array (list): array of zeros and ones that indicates the separation of nodes in two groups\n",
    "\n",
    "    Returns:\n",
    "        nodes_0 (list): list of species names belonging to group A\n",
    "        nodes_1 (list): list of species names belongin to group B\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # We initialize empty lists\n",
    "    nodes_0 = []\n",
    "    nodes_1 = []\n",
    "    \n",
    "    for i in range(len(cut_array)):\n",
    "    \n",
    "        # based on the value of cut_array, separate nodes into the two lists\n",
    "        if cut_array[i] == 0:\n",
    "            nodes_0.append(node_array[i])\n",
    "        elif cut_array[i] == 1:\n",
    "            nodes_1.append(node_array[i])\n",
    "\n",
    "    return(nodes_0, nodes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21f7075-bd72-4127-9eb1-1590e2450261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bit_matrix(old_bit_matrix, cut_array):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Function that updates the bitscore matrix based on the solution array of the DA, \n",
    "    splitting the necessary columns and rows into two matrices in corcondance\n",
    "    with cut_array\n",
    "\n",
    "    Args:\n",
    "        old_bit_matrix (numpy.ndarray): original bitscore matrix to split in two\n",
    "        cut_array (list): solution of the NMCutDA problem, array consisting of zeros and ones\n",
    "\n",
    "    Returns:\n",
    "        bitscore_matrix_0 (numpy.ndarray): bitscore matrix associated with group A (nodes_0)\n",
    "        bitscore_matrix_1 (numpy.ndarray): bitscore matrix associated with group B (nodes_1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # initialized arrays for the split of indices of columns and rows related\n",
    "    # to array nodes_0 and array nodes_1, respectively\n",
    "    index_0 = []\n",
    "    index_1 = []\n",
    "\n",
    "    # loop that searches for the indices of the columns and rows\n",
    "    # associated to zero (respectively, one)\n",
    "\n",
    "    for i in range(len(cut_array)):\n",
    "\n",
    "        if cut_array[i] == 0:\n",
    "            index_0.append(i)\n",
    "\n",
    "        elif cut_array[i] == 1:\n",
    "            index_1.append(i)\n",
    "\n",
    "    # deletes rows and columns associated with 1 to build bitscore_matrix_0\n",
    " \n",
    "    bitscore_matrix_0 = np.delete(old_bit_matrix, index_1, axis=0)\n",
    "    bitscore_matrix_0 = np.delete(bitscore_matrix_0, index_1, axis=1)\n",
    "\n",
    "    # deletes rows and columns associated with 0 to build bitscore_matrix_1\n",
    "    bitscore_matrix_1 = np.delete(old_bit_matrix, index_0, axis=0)\n",
    "    bitscore_matrix_1 = np.delete(bitscore_matrix_1, index_0, axis=1)\n",
    "\n",
    "    return(bitscore_matrix_0, bitscore_matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db62fd0-c24d-4951-bbde-304f1b766d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nodes(node_array, bitscore_matrix, edges_times, key='0', result=None):\n",
    "\n",
    "    \"\"\" \n",
    "    Recursive function that takes an array of nodes and recursively splits them\n",
    "    by calling the QUBO solver until there is only one node per group. Saves the result\n",
    "    into a dictionary with a code '0010110' that indicates to which group the node has belonged\n",
    "    throughout the process.\n",
    "\n",
    "    Args:\n",
    "        node_array (list): Initial list of nodes.\n",
    "        bitscore_matrix (numpy.ndarray): initial bitscore_matrix corresponding to nodes in node_array.\n",
    "        edges_times (str): 'double' or 'single' if edges should be counted twice or once.\n",
    "        key (str): binary code indicating to which branch the node_array has previously belonged\n",
    "        result (dict): dictionar where each node and its corresponding code (key) is stored.\n",
    "\n",
    "    Returns:\n",
    "        result (dict): final dictionary with all the leaf nodes and their respective codes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializatin of result dictionary, only necessary in the first call to the function\n",
    "    if result is None:\n",
    "        result = {}\n",
    "\n",
    "    # Saves the current node array and its code in the result array\n",
    "    # Result array stores all intermediate node_array lists, not only the leaf nodes\n",
    "    result[key] = node_array\n",
    "\n",
    "    # Stops if there is only one node left in the cluster (final leaf)\n",
    "    if len(node_array)>1:\n",
    "\n",
    "        # Calls the N_cut_func for the current array of nodes\n",
    "        best_min_cut, best_N_cut, best_N_cut_array = N_cut_func(node_array, bitscore_matrix, edges_times)\n",
    "\n",
    "        # Divides the nodes based on the annealer array solution\n",
    "        new_nodes = assign_nodes(node_array, best_N_cut_array)\n",
    "        nodes_0 = new_nodes[0]\n",
    "        nodes_1 = new_nodes[1]\n",
    "\n",
    "        # Updates bit score matrix based on the annealers array solution\n",
    "        # and matches with corresponding nodes array\n",
    "        bitscore_matrices = update_bit_matrix(bitscore_matrix, best_N_cut_array)\n",
    "        bitscore_matrix_0 = bitscore_matrices[0]\n",
    "        bitscore_matrix_1 = bitscore_matrices[1]\n",
    "\n",
    "        # Recursevely calls itself to keep splitting the new nodes\n",
    "        # Saves result in the result array each time\n",
    "        split_nodes(nodes_0, bitscore_matrix_0, edges_times, key + '0', result)\n",
    "        split_nodes(nodes_1, bitscore_matrix_1, edges_times, key + '1', result)\n",
    "\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcccd0d-e9c9-45ca-8d2c-3355e2e2e52e",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508172a7-49ca-47eb-8d7a-db26637644dc",
   "metadata": {},
   "source": [
    "## Phylogenetic tree reconstruction\n",
    "\n",
    "Now that we have our final result array, let us reconstruct the tree with the binary code we have implemented. Later, we will use the BioPython package to visualize the results, once we have them in newick format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43019bfe-1526-4c36-a50a-ad67d60022e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports all the tools related to the bioanalysis of the phylogenetic trees\n",
    "from Bio import Phylo\n",
    "import dendropy\n",
    "from dendropy.calculate import treecompare\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.stats import entropy\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb1a6b-1c74-495f-9842-c155c5fa329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGES RELATED TO R\n",
    "# imports the metric \"Clustering distance\" directly from R\n",
    "import os\n",
    "os.environ['R_HOME'] = r'<path_to_R>\\R\\R-4.5.0'\n",
    "from rpy2.robjects import r, globalenv\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "ape = importr('ape')\n",
    "treedist = importr('TreeDist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0555bdd8-b2f3-43c4-81ef-8da0efce5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_real_tree(filename):\n",
    "\n",
    "    \"\"\"   \n",
    "    Function that takes an Excel file and imports all the trees by column.\n",
    "\n",
    "    Args:\n",
    "        filename (str): path to the file that contains the trees.\n",
    "\n",
    "    Returns:\n",
    "        row_list (list): list containing all the trees in the file in newick format.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Open up the Excel file\n",
    "    workbook = load_workbook(filename)\n",
    "    \n",
    "    # Get the first sheet\n",
    "    worksheet = workbook.worksheets[0]\n",
    "    \n",
    "    row_list = []\n",
    "    \n",
    "    # Read file by rows\n",
    "    for r in worksheet.rows:\n",
    "        column = [cell.value for cell in r]\n",
    "        row_list.append(column)\n",
    "    \n",
    "    return(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f2b582-b6cb-4e52-9948-c5645972de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(tree):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that takes out the intermediate node names from the newick format, leaving\n",
    "    only the leaf names.\n",
    "\n",
    "    Args:\n",
    "        tree (str): tree in newick format\n",
    "\n",
    "    Returns:\n",
    "        tree_root (str): pruned tree in newick format\n",
    "    \"\"\"\n",
    "\n",
    "    # substitutes string of the shape ...)NAME_OF_NODE_0001:0.1...\n",
    "    # for ...):0.1... (standard format with only leave names)\n",
    "\n",
    "    tree_nodes = re.sub(r'\\)\\s*[A-Za-z0-9\\._]+:', '):', tree)\n",
    "    tree_root = re.sub(r'\\)\\s*[A-Za-z0-9\\._]+;', ');', tree_nodes)\n",
    "\n",
    "    return(tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11c98ffe-3c7d-42bc-9445-4e35080844d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_newick(tree_dict, branch_length=1.0):\n",
    "\n",
    "    \"\"\"   \n",
    "    Function that transforms the reconstrcted tree dictionary in binary code (result) into newick format.\n",
    "\n",
    "    Args:\n",
    "        tree_dict (dict): dictionary containing only the leaf nodes, of the shape \n",
    "            {'00101': species_1, '10101': species_2, ...}\n",
    "        branch_length (float): default branch length in case branch lengths are not provided.\n",
    "\n",
    "    Returns:\n",
    "        tree_newick (str): tree in newick format\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def insert_path(tree, path, name):\n",
    "        \"\"\"\n",
    "        Inserts a species into the nested tree dictionary following the binary path.\n",
    "        \n",
    "        Args:\n",
    "            tree (dict): The current level of the tree.\n",
    "            path (str): Binary string representing the path.\n",
    "            name (str): Species name to insert.\n",
    "        \"\"\"\n",
    "        for direction in path[:-1]:\n",
    "            if direction not in tree:\n",
    "                tree[direction] = {}\n",
    "            tree = tree[direction]\n",
    "        tree[path[-1]] = name\n",
    "\n",
    "    def build_newick(subtree):\n",
    "        \"\"\"\n",
    "        Recursively builds the Newick string from the nested tree dictionary.\n",
    "\n",
    "        Args:\n",
    "            subtree (dict or str): Current subtree or species name.\n",
    "\n",
    "        Returns:\n",
    "            str: Newick string for the subtree.\n",
    "        \"\"\"\n",
    "        if isinstance(subtree, str):\n",
    "            return f'{subtree}:{branch_length}'\n",
    "        children = [build_newick(child) for child in subtree.values()]\n",
    "        return f'({','.join(children)}):{branch_length}'\n",
    "\n",
    "    # Build the nested tree structure from the binary paths\n",
    "    root = {}\n",
    "    for path, species_list in tree_dict.items():\n",
    "        for species in species_list:\n",
    "            insert_path(root, path, species)\n",
    "\n",
    "    # Convert the nested tree to Newick format\n",
    "    return build_newick(root) + ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8baec0-3fd3-41b5-b40e-777668964d33",
   "metadata": {},
   "source": [
    "### Percentage of correctly reconstructed tree using Robinson_Foulds distance\n",
    "\n",
    "In order to measure the percentage of similarity between the real tree and the reconstructed one, we use the unweighted Robinson-Fould distance and the formula\n",
    "\n",
    "$$ percentage_{correct} = \\left( 1- \\frac{Robinson-Foulds \\ distance}{2N-6}\\right)*100, $$\n",
    "\n",
    "where $N$ denotes the total number of external tips and $2N-6$ represents the maximal possible distance two trees can take. Therefore, this formula measures how many branches are recovered in the reconstructed tree compared with the true tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53f52c0c-1579-4c59-a6dd-504f18c08a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_rf(tree_real, tree_reconstructed, len_nodes):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Function that calculates the Robinson-Foulds distance as a percentage between\n",
    "    two trees (real and reconstructed).\n",
    "\n",
    "    Args:\n",
    "        tree_real (str): real tree in newick format.\n",
    "        tree_reconstruced (str): reconstructed tree in newick format.\n",
    "        len_nodes (int): number of nodes of the tree.\n",
    "\n",
    "    Returns:\n",
    "        percentage (float): percentage of correct reconstruction.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # shared_data creates a shared taxon space of node names for the two trees to use\n",
    "    shared_taxa = dendropy.TaxonNamespace()\n",
    "\n",
    "    # read trees in newick format into the dendropy syntax\n",
    "    tree1 = dendropy.Tree.get(data = tree_real, schema=\"newick\", taxon_namespace = shared_taxa)\n",
    "    tree2 = dendropy.Tree.get(data = tree_reconstructed, schema=\"newick\", taxon_namespace = shared_taxa)\n",
    "\n",
    "    # calculate robinson-foulds distance\n",
    "    robinson_foulds_distance = treecompare.symmetric_difference(tree1, tree2)\n",
    "\n",
    "    # implement percentage formula\n",
    "    # divide by total number of possible branches\n",
    "    percentage = 100 - robinson_foulds_distance*100/(2*len_nodes-6)\n",
    "\n",
    "    return(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd42156",
   "metadata": {},
   "source": [
    "### Percentage of correctly reconstructed tree using Clustering distance\n",
    "\n",
    "Sometimes, the Robinson-Foulds distance may not be an appropiate measure, as it has been critisized to yield biased results. It may not escalate well with a large number of nodes and may omit appropiate clusters if a partition close to the root is not correctly reconstructed. Thus, the Clustering Info Distace has been proposed as an alternative for the Robinson-Foulds distance in order to measure the percentage of correct reconstruction.\n",
    "\n",
    "The Clustering Distance measures the correctly recovered clusters based on information theory metrics. It is implemented in R in the TreeDist library, so we have imported the function directly into python using the $\\verb|rpy2|$ package. The function $\\verb|ClusteringInfoDistace|$ can be normalized and returns a value $0$ when two trees are identical, therefore, we have implemented the percentage as\n",
    "\n",
    "$$  percentage_{correct} = \\left( 1- Clustering \\ distance \\right)*100. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187e7bfc-a0b0-477d-a359-91e5385edf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_cd(tree_real, tree_reconstructed):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Function that calculates the Clustering distance as a percentage between\n",
    "    two trees (real and reconstructed).\n",
    "\n",
    "    Args:\n",
    "        tree_real (str): real tree in newick format.\n",
    "        tree_reconstruced (str): reconstructed tree in newick format.\n",
    "\n",
    "    Returns:\n",
    "        percentage (float): percentage of correct reconstruction.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # read trees in the appropiate package format\n",
    "    tree1 = ape.read_tree(text=tree_real)\n",
    "    tree2 = ape.read_tree(text=tree_reconstructed)\n",
    "\n",
    "    # calculathe the clustering distance\n",
    "    dist_r = treedist.ClusteringInfoDistance(tree1, tree2, normalize=True)\n",
    "    \n",
    "    # make the result a float\n",
    "    distance = float(dist_r[0])\n",
    "\n",
    "    # the result indicates how dissimilar the trees are, so we calculate the inverse\n",
    "    \n",
    "    return((1-distance)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26b51018-06de-43a2-9687-5599a52432cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(tree, file_save):\n",
    "\n",
    "    \"\"\"   \n",
    "    Function to visualize a tree using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        tree (str): tree to visualize in newick format.    \n",
    "        file_save (str): path to output file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # read tree in newick format into Phylo syntax\n",
    "    handle_tree = StringIO(tree)\n",
    "    tree = Phylo.read(handle_tree, 'newick')\n",
    "\n",
    "    # build plot and save output\n",
    "    fig = plt.figure(figsize=(20,18))\n",
    "    axes = fig.add_subplot(1,1,1)\n",
    "    Phylo.draw(tree, do_show=False, axes=axes)\n",
    "    plt.savefig(file_save +'.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8fb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_branch_length(tree_file):\n",
    "\n",
    "    \"\"\"   \n",
    "    Function that calculates the mean branch length and standard deviation of a certain tree.\n",
    "\n",
    "    Args:\n",
    "        tree-file (str or Phylo tree): tree in newick format or already read as a Phylo tree.\n",
    "\n",
    "    Returns:\n",
    "        mean_length (float): mean branch length of the tree.\n",
    "        std_length (float): standard deviation of the branch lengths of the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    # checks if the tree is in string format and if so, \n",
    "    # converts it to Phylo format\n",
    "    if isinstance(tree_file, str) is True:\n",
    "        tree = Phylo.read(StringIO(tree_file), 'newick')\n",
    "    else:\n",
    "        tree = tree_file\n",
    "\n",
    "    # creates a list with all the branch lengths\n",
    "    lengths = [clade.branch_length for clade in tree.find_clades() if clade.branch_length is not None]\n",
    "\n",
    "    # ignores empty branches\n",
    "    if not lengths:\n",
    "        return None, None\n",
    "\n",
    "    # calculates mean and standard deviation\n",
    "    mean_length = np.mean(lengths)\n",
    "    std_length = np.std(lengths)\n",
    "\n",
    "    return mean_length, std_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa8cb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_branch_percentage_table(filename, header=None, data_rows=[]):\n",
    "    \"\"\"\n",
    "    Writes a table with the given header and data_rows to filename.\n",
    "    Each row should be a list: [filter_label, species, avg_branch_length, std_branch_length, nodes, percentage, std_percentage]\n",
    "    \"\"\"\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        # Write header\n",
    "        if header:\n",
    "            f.write('\\t'.join(header) + '\\n')\n",
    "        # Write rows\n",
    "        else:\n",
    "            for row in data_rows:\n",
    "                f.write('\\t'.join(str(item) for item in row) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149186ed-d2f6-4960-aac9-7d6bfd7db636",
   "metadata": {},
   "source": [
    "## EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49122220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(directory_of_tsv, input_file, file_real_trees):\n",
    "\n",
    "    \"\"\"   \n",
    "    Main function that runs the entire process of tree reconstruction and comparison with the real tree.\n",
    "\n",
    "    Args:\n",
    "        directory_of_tsv (str): path to the directory containing the .tsv files.\n",
    "        input_file (str): name of the .tsv file to process.\n",
    "        file_real_trees (str): path to the excel file containing the real trees.    \n",
    "\n",
    "    Returns:\n",
    "        mean_percentage (float): mean percentage of correct reconstruction over 5 repetitions.\n",
    "        std_percentage (float): standard deviation of the percentage of correct reconstruction over 5 repetitions.\n",
    "        branch_length (float): mean branch length of the real tree.\n",
    "        branch_std (float): standard deviation of the branch lengths of the real tree.\n",
    "    \"\"\"\n",
    "\n",
    "    real_tree_lists = import_real_tree(file_real_trees)\n",
    "\n",
    "    # applies the sequence of functions to reconstruct the tree\n",
    "    nodes, bitscore_matrix = import_from_tsv(directory_of_tsv+ '\\\\' + input_file)       # extracts nodes and bitscore matrix\n",
    "    repetitions = []\n",
    "    \n",
    "    # runs several repetitions for statistics\n",
    "    for i in range(5):\n",
    "        time_inic = time.time()\n",
    "        tree_dict = split_nodes(nodes, bitscore_matrix, 'double')   # WARNING!!! quite 'mincut' en los argumentos de esta funcion           # splits the nodes with the Digital Annealer\n",
    "        time_fin = time.time()\n",
    "        leaves_dict = {k: v for k, v in tree_dict.items() if len(v) == 1}                # gets rid of intermediate nodes (only leaves remain)\n",
    "        reconstructed_tree = dict_to_newick(leaves_dict, branch_length=1.0)              # turns dictionary into newick format\n",
    "\n",
    "        ### REAL TREE ###\n",
    "\n",
    "        # gets real tree with the same name from .xslx file \n",
    "        input_file_name = input_file.replace(\".tsv\", \"\")\n",
    "        species = re.sub(r'^[^_]+_|_[^_]+$', '', input_file_name)\n",
    "        species_list = [sp[0] for sp in real_tree_lists]\n",
    "        index_tree = species_list.index(species)\n",
    "        real_tree = prune(real_tree_lists[index_tree][3])                                 # intermediate nodes get pruned out\n",
    "\n",
    "        # calculates the percentage of correct branches between the two trees\n",
    "        percentage = percentage_cd(real_tree, reconstructed_tree)\n",
    "        repetitions.append(percentage)\n",
    "\n",
    "    # calculates mean and std of the percentages\n",
    "    mean_percentage = sum(repetitions)/len(repetitions)\n",
    "    std_percentage = np.std(repetitions)\n",
    "\n",
    "    # calculates branch length for statistics\n",
    "    branch_length, branch_std = calculate_branch_length(real_tree)\n",
    "\n",
    "    return(mean_percentage, std_percentage, branch_length, branch_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51799569-7e0b-4e97-98e5-2c85455c4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory of .tsv files\n",
    "directory_of_tsv = r'<path_to_tsv_files>'\n",
    "\n",
    "# specify directory of output txt and jpg\n",
    "output_file = r'<path_to_output_files>'\n",
    "\n",
    "# specify excel file of real trees in newick format\n",
    "file_real_trees = r'<path_to_real_trees_excel_file>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7314969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: 1-7750_Phy00EB5NQ_BOVIN_nd.tsv\n",
      "Percentage= 56.62321117430851\n",
      "Std= 0.0\n",
      "-----------------------------\n",
      "Species: 1-8106_Phy0002C9D_BOVIN_nd.tsv\n",
      "Percentage= 37.779230043254096\n",
      "Std= 0.5164254198050817\n",
      "-----------------------------\n",
      "Species: 1-8112_Phy00EB58T_BOVIN_nd.tsv\n",
      "Percentage= 63.79204689147275\n",
      "Std= 0.0\n",
      "-----------------------------\n",
      "Species: 1-8243_Phy003JNZY_BOVIN_nd.tsv\n",
      "Percentage= 52.567579071421335\n",
      "Std= 0.0\n",
      "-----------------------------\n",
      "Species: 1-9069_Phy00EB6SE_BOVIN_nd.tsv\n",
      "Percentage= 61.14273304038684\n",
      "Std= 1.0355086526991637\n",
      "-----------------------------\n",
      "Species: 2-0593_Phy0001YCX_BOVIN_nd.tsv\n",
      "Percentage= 21.74831777882581\n",
      "Std= 0.33132607494837435\n",
      "-----------------------------\n",
      "Species: 2-1864_Phy001QCU3_BOVIN_nd.tsv\n",
      "Percentage= 63.91740814349485\n",
      "Std= 2.2281587086577153\n",
      "-----------------------------\n",
      "Species: 2-3466_Phy00EB78E_BOVIN_nd.tsv\n",
      "Percentage= 47.086966955442854\n",
      "Std= 0.0\n",
      "-----------------------------\n",
      "Species: 2-5618_Phy00693C3_BOVIN_nd.tsv\n",
      "Percentage= 42.9260211125112\n",
      "Std= 0.0\n",
      "-----------------------------\n",
      "Species: 2-9178_Phy00696K1_BOVIN_nd.tsv\n",
      "Percentage= 45.0788188058308\n",
      "Std= 0.0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "### LAUNCH ###\n",
    "\n",
    "# set up header for the results table\n",
    "header = [\"species\", \"av_branch\", \"std_branch\", \"nodes\", \"av_perc\", \"std_perc\"]\n",
    "write_branch_percentage_table(output_file, header=header)\n",
    "\n",
    "# gets list of .tsv files to explore\n",
    "tsv_files = [f for f in os.listdir(directory_of_tsv) if f.endswith('.tsv')]\n",
    "tsv_files_every_5 = tsv_files[::1]  # Take every 5th file for quick scan\n",
    "\n",
    "# explores tsv files one by one\n",
    "for file in tsv_files_every_5:\n",
    "    input_file = os.fsdecode(file)\n",
    "    if input_file.endswith(\".tsv\"):\n",
    "\n",
    "        # gets species name and number of nodes for table\n",
    "        species_name = re.sub(r'^[^_]+_|_[^_]+$', '', input_file)\n",
    "        nodes = import_from_tsv(directory_of_tsv + '\\\\' + input_file)[0]\n",
    "\n",
    "        input_file_name = input_file.replace(\".tsv\", \"\")\n",
    "        real_tree_lists = import_real_tree(file_real_trees)\n",
    "        # species = re.sub(r'^\\d+_', '', input_file_name)\n",
    "        species = re.sub(r'^[^_]+_|_[^_]+$', '', input_file_name)\n",
    "        species_list = [sp[0] for sp in real_tree_lists]\n",
    "        index_tree = species_list.index(species)\n",
    "        newick_real = prune(real_tree_lists[index_tree][3])  \n",
    "\n",
    "        branch_length, branch_std = calculate_branch_length(newick_real)\n",
    "\n",
    "        if branch_length >= 1.7749:\n",
    "\n",
    "            av_perc, std_perc, av_branch, std_branch = main(directory_of_tsv, input_file, file_real_trees)\n",
    "\n",
    "            # saves row for the result table\n",
    "            data_rows = [\n",
    "                            [species_name, \n",
    "                            round(av_branch, 4),\n",
    "                            round(std_branch, 4), \n",
    "                            len(nodes),\n",
    "                            round(av_perc, 4),\n",
    "                            round(std_perc, 4)\n",
    "                            ]\n",
    "                        ]\n",
    "            \n",
    "            # writes the row in the output file\n",
    "            write_branch_percentage_table(output_file, data_rows=data_rows)\n",
    "\n",
    "            # some prints for checking\n",
    "            print('Species:', input_file)\n",
    "            print('Percentage=', av_perc)\n",
    "            print('Std=', std_perc)\n",
    "            print('-----------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bb2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdba440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0ee54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phylo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
